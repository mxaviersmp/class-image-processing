{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac77286",
   "metadata": {},
   "source": [
    "MC920 / MO443 (Introdução ao Processamento Digital de Imagem)\n",
    "\n",
    "Prof. Hélio Pedrini\n",
    "\n",
    "Matheus Xavier Sampaio - RA 220092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39dd48",
   "metadata": {},
   "source": [
    "# Instruções \n",
    "\n",
    "## Arquivos\n",
    "\n",
    "O arquivo `Trabalho_01.ipynb` possui um notebook executável com os códigos e o relatório do trabalho.\n",
    "\n",
    "O arquivo `Trabalho_01.pdf` possui o notebook em formato `pdf` com o relatório do trabalho.\n",
    "\n",
    "O arquivo `Trabalho_01.py` possui um script com os códigos do trabalho.\n",
    "\n",
    "## Ambiente e Execução\n",
    "\n",
    "O arquivo `environment.yml` pode ser utilizado para criar um ambiente `conda` com todas as dependencias para executar o trabalho.\n",
    "\n",
    "Caso tenha o Anaconda instalado, basta executar o comando: `$ conda env create`\n",
    "\n",
    "Apos instalar o ambiente, ative usando o comando: `$ conda activate mo443`\n",
    "\n",
    "Por fim, execute o script python para criar as imagens com a visualização de cada questão: `$ python Trabalho_01.py`. Para ver as opções possíveis para a execução do script, execute `$ python Trabalho_01.py -h`.\n",
    "\n",
    "Se preferir, abra o notebook e execute uma célula por vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea553d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_url_or_disk(path):\n",
    "    if urlparse(path).scheme:\n",
    "        resp = requests.get(path)\n",
    "        image = np.asarray(bytearray(resp.content), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_GRAYSCALE)\n",
    "    elif Path(path).exists():\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        raise ValueError('caminho deve ser url ou arquivo')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(grid, images, titles, filepath):\n",
    "    plt.figure(figsize=(19, 10))\n",
    "    for i, (img, title) in enumerate(zip(images, titles), start=1):\n",
    "        plt.subplot(*grid, i)\n",
    "        plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(filepath)\n",
    "    plt.savefig(f'{filepath}.png', transparent=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = image_from_url_or_disk('https://www.ic.unicamp.br/~helio/imagens_png/baboon.png')\n",
    "image_2 = image_from_url_or_disk('https://www.ic.unicamp.br/~helio/imagens_png/butterfly.png')\n",
    "\n",
    "# image_1 = image_from_url_or_disk('./bike.jpeg')\n",
    "# image_2 = image_from_url_or_disk('./engine.jpeg')\n",
    "\n",
    "img1_name = 'baboon'\n",
    "img2_name = 'butterfly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_img = np.full_like(image_1, 255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7934f6e",
   "metadata": {},
   "source": [
    "# Processamentos Básicos em Imagens Digitais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images((1, 2), [image_1, image_2], [img1_name, img2_name], 'imagens_originais')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e86910",
   "metadata": {},
   "source": [
    "## Transformação de Intensidade\n",
    "\n",
    "Transformar o espaço de intensidades (nı́veis de cinza) de uma imagem monocromática para:\n",
    "- (i) obter o negativo da imagem, ou seja, o nı́vel de cinza 0 será convertido para 255, o nı́vel 1 para\n",
    "254 e assim por diante\n",
    "- (ii) converter o intervalo de intensidades para [100, 200]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_image(img):\n",
    "    return (img * -1) + 255\n",
    "\n",
    "def clip_image(img, min_v, max_v):\n",
    "    return np.clip(img, min_v, max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7609da",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (1, 3), \n",
    "    [image_1, negative_image(image_1), clip_image(image_1, 100, 200)],\n",
    "    ['original', 'negativo da imagem', 'imagem transformada'],\n",
    "    'q1_transformacao_de_intensidade'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca2879",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Para obter o negativo da imagem, basta multiplicar os valores por -1 e somar 255. Isso faz com que os valores próximos a 0 subam para 255 e os mais altos descam a 0, invertendo a intensidade das cores. Para ob\n",
    "\n",
    "**Implementação:**\n",
    "Para criar a imagem negativa, basta multiplicar a imagem por -1 e somar 255.\n",
    "\n",
    "Para transformar os intervalor, o método `clip` ira cortar os valores fora do intervalo passado.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada e retorna o negativo da imagem.\n",
    "\n",
    "A função criada recebe a imagem e os intervalos mínimo e maximo, retornando a imagem respeitando o novo intervalo\n",
    "\n",
    "\n",
    "**Resultados:**\n",
    "Observando o resultado, a imagem negativa apresenta as intensidades invertidas, enquando na imagem transformada é possivel observar um menor contraste e nivel de detalhe devido a faixa de valores possiveis reduzida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3f352",
   "metadata": {},
   "source": [
    "## Ajuste de Brilho\n",
    "\n",
    "Aplicar a correção gama para ajustar o brilho de uma imagem monocromática `A` de entrada e gerar\n",
    "uma imagem monocromática `B` de saı́da. A transformação pode ser realizada:\n",
    "- (a) convertendo-se as intensidades dos pixels para o intervalo de [0, 255] para [0, 1]\n",
    "- (b) aplicando-se a equação $B = A^{(1/γ)}$ \n",
    "- (c) convertendo-se de volta os valores resultantes para o intervalo [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41049041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(img, gamma):\n",
    "    return (((img / 255) ** (1/gamma)) * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8681d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (1, 4), \n",
    "    [image_1] + [gamma_correction(image_1, gamma) for gamma in [1.5, 2.5, 3.5]],\n",
    "    ['original', 'γ = 1.5', 'γ = 2.5', 'γ = 3.5'],\n",
    "    'q2_ajuste_de_brilho'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea946f",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Para alterar o fator de brilho da imagem, primeiro é preciso converter a escala para ponto flutuante entre 0 e 1, fazendo isso dividindo pelo valor máximo de intensidade, que é 255 por estar representado em 8 bits.\n",
    "\n",
    "Com os valores no novo intervalo, após aplicar a formula para ajuste de brilho, as intensidades de cor são convertidas para a representação de 8 bits.\n",
    "\n",
    "**Implementação:**\n",
    "Com o uso dos `arrays` pode realizar cada operação necessária, primeiro normalizando os valores dividindo por 255, após isso aplicando a formula elevando a $(1/Y)$, em seguida retornando a escala original multiplicando por 255, e modificando a representação ao modificar o tipo para inteiro de 8 bits.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada e valor de gamma desejado, retornando a imagem transformada com o brilho alterado.\n",
    "\n",
    "**Resultados:**\n",
    "Essa transformação eleva os valores de intensidade de cor dos pixels de acordo com o valor de $γ$, aumentando o valor de intensidade, e com isso a percepção de brilho e claridade na imagem ao aumentar o valor de $γ$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3995d3",
   "metadata": {},
   "source": [
    "## Quantização de Imagens\n",
    "\n",
    "Quantização refere-se ao número de nı́veis de cinza usados para representar uma imagem mono-cromática. A quantização está relacionada à profundidade de uma imagem, a qual corresponde\n",
    "ao número de bits necessários para armazenar a imagem. Represente uma imagem com diferentes\n",
    "nı́veis de quantização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55589782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantitize_image(img, levels):\n",
    "    if not (0 < levels <= 256):\n",
    "        raise ValueError('`levels` deve estar ]0, 256]')\n",
    "    quantitize = np.arange(0, 256, int(256 / levels))\n",
    "    quantitized = quantitize[np.digitize(img, quantitize) - 1]\n",
    "    quantitized = (quantitized / quantitize.max()) * 255\n",
    "    return quantitized.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1851dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (3, 3),\n",
    "    [empty_img, image_1, empty_img] + [quantitize_image(image_1, level) for level in [64, 32, 16, 8, 4, 2]],\n",
    "    ['', '256 níveis', '', '64 nı́veis', '32 nı́veis', '16 nı́veis', '8 nı́veis', '4 nı́veis', '2 nı́veis'],\n",
    "    'q3_quantizacao_de_imagens'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782379fb",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Quantizar a imagem é aplicar uma transformação da escala de cinza, no caso de imagens monocromáticas. Essa transformação altera a percepção da quantidade de bits utilizada para representar as cores em uma imagem. \n",
    "\n",
    "Para alcançar este efeito, podemos criar uma distribuição dos valores de intensidade da imagem original, incrementando os passos de acordo com o nível desejado. Isso significa que, como uma imagem de 8bits pode assumir 256 níveis, criamos uma distribuição de 0 a 255. Reduzir para uma representção de 4bits significa que cada píxel pode possuir 16 níveis de intensidade. Com isso, modificando o passo da distribuição alteramos os valores que cada pixel pode assumir. Por exemplo, se 8 bits pode assumir valores `[0, 1, 2, ..., 254, 255]`, 4 bits pode assumir os valores `[0, 16, 32, ..., 240, 255]`. Com essas novas faixas de valores, podemos transformar cada píxel da imagem original no valor correspondente na nova representação. Assim, se uma faixa da imagem de 8 bits possui valores `[76, 114,  46,  46,  97]`, sua representaão em 4 bits seria `[ 64, 112,  32,  32,  96]`.\n",
    "\n",
    "**Implementação:**\n",
    "Para a implementação utilizando o `numpy`, é criada um arranjo de `0 a 256`, com um passo de acordo com o nível desejado. Esse arranjo é utilizado para mapear os valores da imagem original as novas intensidades, com a ajuda do método `digitize`, que retorna os índices das faixas aos quais cada valor na matriz de entrada pertence. Com os valores quantizados, é aĺicada uma normalização para transformar os valores na faixa de 0 a 255.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada e o nível de intensidade desejado, retornando a imagem transformada com \n",
    "os novos valores.\n",
    "\n",
    "**Limitações:** O valor de nivel de respeitar o intervalo $]0, 256]$.\n",
    "\n",
    "**Resultados:**\n",
    "Como observado no resultado, reduzir a quantidade de bits resulta em uma menor variabilidade de cores, criando uma imagem menos detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe0fc8",
   "metadata": {},
   "source": [
    "## Planos de Bits\n",
    "\n",
    "Extrair os planos de bits de uma imagem monocromática. Os nı́veis de cinza de uma imagem\n",
    "monocromática com m bits podem ser representados na forma de um polinômio de base 2:\n",
    "\n",
    "$a_{m−1} 2^{m−1} + a_{m−2} 2^{m−2} + . . . + a_1 2^{1} + a_0 2^{0}$\n",
    "\n",
    "O plano de bits de ordem 0 é formado pelos coeficientes a 0 de cada pixel, enquanto o plano de\n",
    "bits de ordem $m − 1$ é formado pelos coeficientes $a_{m−1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitplan_image(img, bp):\n",
    "    h, w = img.shape\n",
    "    img = np.unpackbits(img.reshape(-1, 1), axis=1, bitorder='little')\n",
    "    if not (0 <= bp <= 7):\n",
    "        raise ValueError('bp deve estar entre [0, 7]')\n",
    "    bitplan = img[:, bp] * (2**bp)\n",
    "    bitplan = ((bitplan / 2**bp) * 255).astype('uint8')\n",
    "    return bitplan.reshape(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (1, 4),\n",
    "    [image_1] + [bitplan_image(image_1, bp) for bp in [0, 4, 7]],\n",
    "    ['original','plano de bit 0', 'plano de bit 4', 'plano de bit 7'],\n",
    "    'q4_planos_de_bits'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b725d9",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "O plano de bits é um corte na imagem, extraindo o valor representado pelo bit correspondente. Isso significa que, se o pixel de uma imagem possui o valor $137$, em 8 bits, sua representação binária é $10001001$. Ao cortar essa imagem no plano 3, o valor desse pixel será representado pelo valor do bit 3, multiplocado pela a potencia $2^3$, que no caso seria 8. Assim, o valor máximo de intensidade dessa imágem é 8.\n",
    "\n",
    "**Implementação:**\n",
    "Utilizamos do método `unpackbits` para transformar cada valor de pixel em nossa imagem em um array com sua representação binária. Para isso, modificamos o formato de nossa imagem, isolando cada pixel em uma linha. Para facilitar a aritmética, escolhemos representar de forma binária little-endian. Com a imagem representada em bits, escolhemos o bit do plano desejado, multiplicando pela potencia de 2. O resultado é então normalizado e reformatado para as dimensões da imagem.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada e o plano que deseja realizar o corte, retornando a imagem o corte nesse plano.\n",
    "\n",
    "**Limitações:** O valor do plano de bits de respeitar o intervalo $[0, 7]$.\n",
    "\n",
    "**Resultados:**\n",
    "Como observado no resultado, cada plano exibe apenas pixels que possuem o bit representado naquele nivel. No caso do plano 0, pixel pares são exibidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e78bc",
   "metadata": {},
   "source": [
    "## Mosaico\n",
    "\n",
    "Construir um mosaico de 4 × 4 blocos a partir de uma imagem monocromática. A disposição dos\n",
    "blocos deve seguir a numeração mostrada:\n",
    "\n",
    "|    |    |    |    |   |   |   |    |    |    |   |\n",
    "|----|----|----|----|---|---|---|----|----|----|---|\n",
    "| 1  |  2 |  3 |  4 |   |   |   | 6  | 11 | 13 | 3 |\n",
    "| 5  |  6 |  7 |  8 |   | &rarr;  |   | 8  | 16 | 1  | 9 |\n",
    "| 9  | 10 | 11 | 12 |   |   |   | 12 | 14 | 2  | 7 |\n",
    "| 13 | 14 | 15 | 16 |   |   |   | 4  | 15 | 10 | 5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1972392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_image(img, n_blocks, new_order):\n",
    "    h, w = img.shape\n",
    "\n",
    "    if h != w:\n",
    "        raise ValueError('Imagem deve ser quadrada.')\n",
    "    if n_blocks <= 0 or (h * w) % n_blocks > 0:\n",
    "        raise ValueError('numero de blocos dever ser divisor das dimensões')\n",
    "        \n",
    "    block_size = h // n_blocks\n",
    "\n",
    "    shape = (\n",
    "        h // block_size,\n",
    "        w // block_size,\n",
    "        block_size,\n",
    "        block_size,\n",
    "    )\n",
    "    strides = (\n",
    "        w * block_size,\n",
    "        block_size,\n",
    "        w,\n",
    "        1\n",
    "    )\n",
    "\n",
    "    blocks = np.lib.stride_tricks.as_strided(\n",
    "        img,\n",
    "        shape=shape,\n",
    "        strides=strides\n",
    "    )\n",
    "    blocks = blocks.reshape(-1, block_size, block_size)\n",
    "    blocks = blocks[new_order]\n",
    "    blocks = blocks.reshape(n_blocks, n_blocks, block_size, block_size)\n",
    "    blocks = blocks.swapaxes(1, 2)\n",
    "\n",
    "    return blocks.reshape(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed106632",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 4\n",
    "\n",
    "new_order = np.array([\n",
    "    [6, 11, 13, 3],\n",
    "    [8, 16, 1, 9],\n",
    "    [12, 14, 2, 7],\n",
    "    [4, 15, 10, 5]\n",
    "]) - 1\n",
    "\n",
    "image_1_mosaic = mosaic_image(image_1, n_blocks, new_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf65a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (1, 2),\n",
    "    [image_1, image_1_mosaic],\n",
    "    ['original', 'mosaico'],\n",
    "    'q5_mosaico'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b90804",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Dividir a imagem em diferentes segmentos quadriculares, reorganizando esses segmentos.\n",
    "\n",
    "**Implementação:**\n",
    "Primeiramente é preciso segmentar a imagem em blocos. Para isso, podemos dividir a imagem em novas regiões, para que possamos acessar cada região como uma matrix. Assim, cada indice da nova matriz de regioes contem um segmento da imagem. Esta segmentação não é trivial pois a imagem é representaga em segmentos contínuos de pixels. Para realizar essa divisão em blocos, precisamos modificar como os arrays. O `numpy` utiliza de passos, ou `strides`, para determinar onde termina cada linha. Modificando esse valor, em conjunto com o formato, é possivel realizar essa divisão em blocos.\n",
    "\n",
    "O novo tamanho da imagem será o tamanho da matriz de blocos e o tamanho dos blocos, `(# blocos, # blocos, tamanho blocos, tamanho blocos)`. Uma imagem 8 * 8, dividida em 4 blocos, resultaria em um segmentação tamanho `(4, 4, 2, 2)`, acessando o segmento `[0, 0]` retornaria o bloco superior direito, de tamanho `(2, 2)`. Para os passos, o passo inicial é a largura pelo tamanho do bloco, o segundo passo é o tamanho de cada bloco, o terceiro é a largura da imagem, com o quanto sendo o canal de cor. No exemplo, o primeiro passo tem tamanho 16, que é a `distancia de um bloco a seu adjacente vertical`. O segundo passo tem tamanho 2, a `distancia de um bloco a seu adjacente horizontal`. O terceiro é a `distancia de um pixel ao proximo em cada linha`.\n",
    "\n",
    "Com a imagem segmentada, transformamos a matrix em um vetor, apenas para facilitar sua reordenação. Essa ordem é dada por uma sequencia de numeros determinando o indice de cada segmento. Com o mosaico reorganizado, agora é feita a união da imagem. Primeiro o formato é transfomado novamente em uma matriz de segmentos. \n",
    "Para 'colar' a imagem, é preciso inverter a ordem dos eixos dos blocos, trocando o segundo com o terceiro eixo. Por fim, modificamos novamente o formato da imagem para o original.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada, a quantidade de blocos por linha e a nova ordenação do mosaco, retornando o novo mosaico.\n",
    "\n",
    "**Limitações:** A imagem deve ser quadrada e o numero de blocks deve ser um divisor das dimensões.\n",
    "\n",
    "**Resultados:** Como observado no resultado, a imagem foi segmentada em blocos, reordenados de acordo com a escolha do usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a53ef7",
   "metadata": {},
   "source": [
    "## Combinação de Imagens\n",
    "\n",
    "Combinar duas imagens monocromáticas de mesmo tamanho por meio da média ponderada de\n",
    "seus nı́veis de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(img1, f1, img2, f2):\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError('Imagens devem possuir mesmas dimensões.')\n",
    "    return (np.clip(img1 * f1, 0, 255) + np.clip(img2 * f2, 0, 255)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (2, 3),\n",
    "    [image_1, empty_img, image_2] + [\n",
    "        combine_images(image_1, f1, image_2, f2)\n",
    "        for f1, f2 in [(0.2, 0.8), (0.5, 0.5), (0.8, 0.2)]\n",
    "    ],\n",
    "    ['A', '', 'B', '0.2*A + 0.8*B', '0.5*A + 0.5*B', '0.8*A + 0.2*B'],\n",
    "    'q6_combinacao_de_imagens'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18e967",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Combinar as imagens de modo que a imagem resultado possua uma porcentagem de cada.\n",
    "\n",
    "**Implementação:**\n",
    "Primeiramente é multiplicada cada imagem por seu fator, limitando o resultado a faixa de valores de intensidade. Apos isso, as imagens são combinadas apenas somando ambas.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "As imagens e seus fatores de multiplicação, com imagem 1 e fator 1, imagem 2 e fator 2.\n",
    "\n",
    "**Limitações:** Imagens devem possuir as mesmas dimensões.\n",
    "\n",
    "**Resultados:** Como observado no resultado, as imagems resultantes são resultado de uma combinação entre as duas. A imagem com maior peso é mais prevalente e visível no resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ecb22",
   "metadata": {},
   "source": [
    "## Filtragem de Imagens\n",
    "\n",
    "Uma operação de filtragem aplicada a uma imagem digital é altera localmente os valores de intensidade dos pixels da imagem levando-se em conta tanto o valor do pixel em questão quanto\n",
    "valores de pixels vizinhos. No processo de filtragem, utiliza-se uma operação de convolução de\n",
    "uma máscara pela imagem. Este processo equivale a percorrer toda a imagem alterando seus\n",
    "valores conforme os pesos da máscara e as intensidades da imagem.\n",
    "\n",
    "Aplicar os seguintes filtros (individualmente) em uma imagem digital monocromática:\n",
    "\n",
    "|    |    |    |    |   |   |    |    |    |    |\n",
    "|----|----|----|----|---|---|----|----|----|----|\n",
    "|    | -1 | -1 | -1 |   |   |    | -1 | -2 | -1 |\n",
    "| h1 | -1 | 8  | -1 |   |   | h2 | 0  | 0  | 0  |\n",
    "|    | -1 | -1 | -1 |   |   |    | 1  | 2  | 1  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dad802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel):\n",
    "    h, w = img.shape\n",
    "    kh, kw = kernel.shape\n",
    "    \n",
    "    if kh != kw:\n",
    "        raise ValueError('kernel deve ser quadrado')\n",
    "    \n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    convoluted_img = np.zeros_like(img)\n",
    "    \n",
    "    k = (kh - 1) // 2\n",
    "\n",
    "    image_padded = np.zeros((h + kh - 1, w + kw - 1))\n",
    "    image_padded[k:-k, k:-k] = img\n",
    "\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            convoluted_img[y, x] = (kernel * image_padded[y: y + kh, x: x + kw]).sum()\n",
    "\n",
    "    return convoluted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42883887",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, 8, -1],\n",
    "    [-1, -1, -1]\n",
    "])\n",
    "h2 = np.float32([\n",
    "    [-1, -2, -1],\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    (2, 3),\n",
    "    [\n",
    "        image_1, convolution(image_1, h1), convolution(image_1, h2),\n",
    "        image_2, convolution(image_2, h1), convolution(image_2, h2),\n",
    "    ],\n",
    "    [\n",
    "        img1_name, 'baboon h1', 'baboon h2',\n",
    "        img2_name, 'butterfly h1', 'butterfly h2'\n",
    "    ],\n",
    "    'q7_filtragem_de_imagens'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fba364",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Aplicar filtros as imagens com o uso de convoluções.\n",
    "\n",
    "**Implementação:**\n",
    "Primeiramente, para calcular a convolução, o filtro é espelhado no centro. Após isso é adicionado um padding a imagem, do tamanho do filtro menos uma unidade. Então são realizadas as convoluções. Para cada indice na imagem, são escolhidos os indices correspondentes na região de vizinhança do tamanho do filtro. Esta região é multiplicada pelo filtro, o resultado é somado e atribuido ao pixel correspondente da imagem com a convolução.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A função criada recebe a imagem de entrada e o filtro que deseja ser aplicado, retornando a nova imagem 'filtrada'.\n",
    "\n",
    "**Limitações:** O filtro deve ser quadrado.\n",
    "\n",
    "**Resultados:** \n",
    "O resultado mostra a imagem original e os resultados dos filtros. Apesar do grande ruído, o filtro `h1` aparenta detectar as bordas das imagem, enquanto o filtro `h2` aparenta detectar arestas horizontais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1505a3",
   "metadata": {},
   "source": [
    "## Entropia\n",
    "\n",
    "Calcular a entropia de uma imagem monocromatica, de acordo com a equação:\n",
    "\n",
    "$H = −\\sum^{Lmax}_{i=0}p_i \\log p_i$\n",
    "\n",
    "em que a distribuição dos nı́veis de intensidade da imagem pode ser transformada em uma função\n",
    "densidade de probabilidade, dividindo-se o número de pixels de intensidade $i$, denotado $n_i$,\n",
    "pelo número total $n$ de pixels na imagem, ou seja $p_i = \\dfrac{n_i}{n}$, em que $\\sum^{Lmax}_{i=0}p_i = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_entropy(img):\n",
    "    if len(img.shape) > 2:\n",
    "        raise ValueError('Imagem deve possuir apenas 1 canal de cor')\n",
    "    hist, _ = np.histogram(img, bins = 256)\n",
    "    hist = hist / img.size\n",
    "    hist_non_zero = hist[hist > 0]\n",
    "    return -np.sum(np.multiply(hist_non_zero, np.log2(hist_non_zero)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A entropia da imagen {img1_name} é {image_entropy(image_1)}')\n",
    "print(f'A entropia da imagen {img2_name} é {image_entropy(image_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd068774",
   "metadata": {},
   "source": [
    "**Idéia:**\n",
    "Calcular a entropia das imagens em escala de cinza.\n",
    "\n",
    "**Implementação:**\n",
    "Primeiramente, é calculado o histograma da imagem, para determinar o quanto de cada intensidade de cinza está presente na imagem. Apos isso, os valores do histograma são divididos pelo tamanho da imagem. As intensidades com valor 0 são removidas do histograma. Por fim, a formula para o calculo da entropia é utilizada.\n",
    "\n",
    "**Chamada e parâmetros:**\n",
    "A imagem para calcular, retornando sua entropia.\n",
    "\n",
    "**Limitações:** A imagem deve possuir apenas 1 canal de cor.\n",
    "\n",
    "**Resultados:** \n",
    "Pelo resultado, podemos inferir que a imagem `baboon` possui mais informação, ou mais detalhes, que a `butterfly`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
